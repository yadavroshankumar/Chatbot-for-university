{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yadavroshankumar/Chatbot-for-university/blob/main/CSIT599_module2_CNN_and_Advanced_Computer_Vision_Exercise_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSIT 599 Module 2 - CNN and Advanced Computer Vision\n",
        "\n",
        "## CNN Architecture Evolution: From LeNet to ResNet\n",
        "### Exercise for Students - SEQUENTIAL LEARNING APPROACH\n",
        "\n",
        "This exercise demonstrates the evolution of CNN architectures:\n",
        "1. Traditional CNN (Basic vanilla CNN)\n",
        "2. LeNet-5 (1998) - The pioneer\n",
        "3. AlexNet (2012) - Deep learning breakthrough\n",
        "4. VGG-16 (2014) - Deep and uniform\n",
        "5. Inception/GoogLeNet (2014) - Multi-scale features\n",
        "6. ResNet (2015) - Skip connections revolution\n",
        "\n",
        "Dataset: CIFAR-10 (32x32 color images, 10 classes)\n",
        "- airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
        "\n",
        "Instructions:\n",
        "1. Fill in the blanks marked with \"# TODO: STUDENT FILL IN\"\n",
        "2. Run each architecture sequentially\n",
        "3. Compare performance and training characteristics\n",
        "4. Understand key innovations in each architecture\n",
        "\n",
        "Key Concepts:\n",
        "- Depth vs Width\n",
        "- Skip connections (ResNet)\n",
        "- Multi-scale features (Inception)\n",
        "- Architectural innovations over time\n"
      ],
      "metadata": {
        "id": "VG4rk7Nvy3_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "P_hJGOh4zPb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1: DATA PREPARATION - CIFAR-10"
      ],
      "metadata": {
        "id": "iOWnZbBW6Xgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 1: DATA PREPARATION - CIFAR-10\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_prepare_cifar10():\n",
        "    \"\"\"\n",
        "    Load and preprocess CIFAR-10 dataset.\n",
        "\n",
        "    CIFAR-10 contains 60,000 32x32 color images in 10 classes:\n",
        "    - 50,000 training images\n",
        "    - 10,000 test images\n",
        "\n",
        "    Returns:\n",
        "        tuple: (x_train, y_train, x_test, y_test, class_names)\n",
        "    \"\"\"\n",
        "    print(\"STEP 1: LOADING CIFAR-10 DATASET\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # Class names\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    print(f\"Training data shape: {x_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Test data shape: {x_test.shape}\")\n",
        "    print(f\"Number of classes: {len(class_names)}\")\n",
        "    print(f\"Classes: {class_names}\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Normalize pixel values to [0, 1] range\n",
        "    x_train = x_train.astype('float32') / ________\n",
        "    x_test = x_test.astype('float32') / ________\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Convert labels to categorical (one-hot encoding)\n",
        "    y_train = keras.utils.to_categorical(y_train, ________)  # 10 classes\n",
        "    y_test = keras.utils.to_categorical(y_test, ________)\n",
        "\n",
        "    print(f\"\\nAfter preprocessing:\")\n",
        "    print(f\"Training data shape: {x_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Pixel value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, class_names\n",
        "\n",
        "def visualize_cifar10_samples(x_train, y_train, class_names):\n",
        "    \"\"\"Visualize sample images from CIFAR-10.\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(20):\n",
        "        plt.subplot(4, 5, i + 1)\n",
        "        plt.imshow(x_train[i])\n",
        "        plt.title(class_names[np.argmax(y_train[i])], fontsize=8)\n",
        "        plt.axis('off')\n",
        "    plt.suptitle('CIFAR-10 Sample Images')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ruRBzUAfzSDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "x_train, y_train, x_test, y_test, class_names = load_and_prepare_cifar10()\n",
        "visualize_cifar10_samples(x_train, y_train, class_names)"
      ],
      "metadata": {
        "id": "M5xtPb5F6O10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2: TRADITIONAL CNN (BASELINE)"
      ],
      "metadata": {
        "id": "RHsnEYSQ6bo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: TRADITIONAL CNN (BASELINE)\n",
        "# ============================================================================\n",
        "\n",
        "def create_traditional_cnn():\n",
        "    \"\"\"\n",
        "    Create a traditional/vanilla CNN as baseline.\n",
        "\n",
        "    Simple architecture:\n",
        "    - 3 Conv blocks (Conv2D + MaxPooling)\n",
        "    - Dense layers\n",
        "    - No special techniques\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled traditional CNN\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 2: BUILDING TRADITIONAL CNN (BASELINE)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = keras.Sequential(name=\"Traditional_CNN\")\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # First Conv Block: 32 filters, (3,3) kernel, 'relu', input_shape=(32,32,3)\n",
        "    model.add(layers.Conv2D(________, (3, 3), activation='________',\n",
        "                           input_shape=(________, ________, ________), padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Second Conv Block: 64 filters, (3,3) kernel, 'relu'\n",
        "    model.add(layers.Conv2D(________, (3, 3), activation='________', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Third Conv Block: 128 filters, (3,3) kernel, 'relu'\n",
        "    model.add(layers.Conv2D(________, (3, 3), activation='________', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Flatten and Dense layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='________'))\n",
        "    model.add(layers.Dense(________, activation='________'))  # 10 classes, softmax\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Compile: optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
        "    model.compile(optimizer='________',\n",
        "                 loss='________',\n",
        "                 metrics=['________'])\n",
        "\n",
        "    print(\"\\nTraditional CNN Architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "6lsI1AZ-zVOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: LeNet-5 (1998) - THE PIONEER"
      ],
      "metadata": {
        "id": "8u4XrHcY6iGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: LeNet-5 (1998) - THE PIONEER\n",
        "# ============================================================================\n",
        "\n",
        "def create_lenet5():\n",
        "    \"\"\"\n",
        "    Create LeNet-5 architecture (adapted for CIFAR-10).\n",
        "\n",
        "    Original LeNet-5 (1998) by Yann LeCun:\n",
        "    - Designed for handwritten digit recognition (MNIST)\n",
        "    - First successful CNN architecture\n",
        "    - Used sigmoid/tanh activation (before ReLU era)\n",
        "\n",
        "    Key features:\n",
        "    - 2 Conv layers\n",
        "    - Average pooling (we'll use MaxPooling for better performance)\n",
        "    - Small network by modern standards\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled LeNet-5 model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 3: BUILDING LeNet-5 (1998)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: First successful CNN architecture!\")\n",
        "\n",
        "    model = keras.Sequential(name=\"LeNet5\")\n",
        "\n",
        "    # First Conv Block (C1: 6 filters, 5x5)\n",
        "    model.add(layers.Conv2D(6, (5, 5), activation='tanh',\n",
        "                           input_shape=(32, 32, 3), padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Second Conv Block (C3: 16 filters, 5x5)\n",
        "    model.add(layers.Conv2D(16, (5, 5), activation='tanh'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(120, activation='tanh'))\n",
        "    model.add(layers.Dense(84, activation='tanh'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nLeNet-5 Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Note: Using tanh activation (original) instead of ReLU\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "o00vH9fYzZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4: AlexNet (2012) - DEEP LEARNING BREAKTHROUGH"
      ],
      "metadata": {
        "id": "Q33dYKNJ6k1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: AlexNet (2012) - DEEP LEARNING BREAKTHROUGH\n",
        "# ============================================================================\n",
        "\n",
        "def create_alexnet():\n",
        "    \"\"\"\n",
        "    Create AlexNet architecture (adapted for CIFAR-10).\n",
        "\n",
        "    Original AlexNet (2012) by Krizhevsky, Sutskever, Hinton:\n",
        "    - Won ImageNet 2012 competition\n",
        "    - Sparked the deep learning revolution\n",
        "    - First to use ReLU activation\n",
        "    - First to use dropout regularization\n",
        "    - Originally designed for 224x224 images\n",
        "\n",
        "    Key innovations:\n",
        "    - ReLU activation (faster training)\n",
        "    - Dropout for regularization\n",
        "    - Local response normalization (we'll skip)\n",
        "    - Overlapping pooling\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled AlexNet model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 4: BUILDING AlexNet (2012)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: ReLU activation + Dropout + Deep network!\")\n",
        "\n",
        "    model = keras.Sequential(name=\"AlexNet\")\n",
        "\n",
        "    # Block 1\n",
        "    model.add(layers.Conv2D(96, (3, 3), activation='relu',\n",
        "                           input_shape=(32, 32, 3), padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
        "\n",
        "    # Block 3, 4, 5\n",
        "    model.add(layers.Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
        "\n",
        "    # Fully connected layers with Dropout\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))  # KEY: Dropout introduced here!\n",
        "    model.add(layers.Dense(4096, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nAlexNet Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Key innovations: ReLU + Dropout!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "DV1W9XMJzckt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5: VGG-16 (2014) - DEEP AND UNIFORM"
      ],
      "metadata": {
        "id": "rpbs2LNX6oVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 5: VGG-16 (2014) - DEEP AND UNIFORM\n",
        "# ============================================================================\n",
        "\n",
        "def create_vgg16():\n",
        "    \"\"\"\n",
        "    Create VGG-16 architecture (simplified for CIFAR-10).\n",
        "\n",
        "    Original VGG-16 (2014) by Simonyan and Zisserman:\n",
        "    - Very deep network (16 weight layers)\n",
        "    - Simple and uniform architecture\n",
        "    - Only 3x3 convolutions throughout\n",
        "    - Multiple conv layers before pooling\n",
        "\n",
        "    Key innovations:\n",
        "    - Depth is important\n",
        "    - Small 3x3 filters work well\n",
        "    - Uniform architecture (easy to understand)\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled VGG-16 model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 5: BUILDING VGG-16 (2014)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Very deep network + Uniform 3x3 filters!\")\n",
        "\n",
        "    model = keras.Sequential(name=\"VGG16\")\n",
        "\n",
        "    # Block 1\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
        "                           input_shape=(32, 32, 3)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nVGG-16 Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Key innovation: Very deep with uniform 3x3 convolutions!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KNh1ouq0zhUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 6: Inception/GoogLeNet (2014) - MULTI-SCALE FEATURES"
      ],
      "metadata": {
        "id": "2uG_ZBml6zQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Inception/GoogLeNet (2014) - MULTI-SCALE FEATURES\n",
        "# ============================================================================\n",
        "\n",
        "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3,\n",
        "                     filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
        "    \"\"\"\n",
        "    Create an Inception module.\n",
        "\n",
        "    Inception module concept:\n",
        "    - Process input at multiple scales simultaneously\n",
        "    - 1x1, 3x3, 5x5 convolutions in parallel\n",
        "    - Concatenate all outputs\n",
        "    - 1x1 convs for dimensionality reduction\n",
        "\n",
        "    This is the KEY innovation of Inception/GoogLeNet!\n",
        "    \"\"\"\n",
        "    # 1x1 convolution branch\n",
        "    conv_1x1 = layers.Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "    # 3x3 convolution branch\n",
        "    conv_3x3 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv_3x3 = layers.Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
        "\n",
        "    # 5x5 convolution branch\n",
        "    conv_5x5 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv_5x5 = layers.Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
        "\n",
        "    # Max pooling branch\n",
        "    pool_proj = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = layers.Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
        "\n",
        "    # Concatenate all branches\n",
        "    output = layers.concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=-1)\n",
        "\n",
        "    return output\n",
        "\n",
        "def create_inception():\n",
        "    \"\"\"\n",
        "    Create Inception/GoogLeNet architecture (simplified for CIFAR-10).\n",
        "\n",
        "    Original Inception/GoogLeNet (2014) by Szegedy et al:\n",
        "    - Winner of ImageNet 2014\n",
        "    - Introduced \"Inception module\"\n",
        "    - Multi-scale feature extraction\n",
        "    - Efficient: fewer parameters than VGG\n",
        "\n",
        "    Key innovation:\n",
        "    - Inception module: parallel convolutions at different scales\n",
        "    - 1x1 convolutions for dimensionality reduction\n",
        "    - Network in network concept\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled Inception model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 6: BUILDING Inception/GoogLeNet (2014)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Multi-scale feature extraction with Inception modules!\")\n",
        "\n",
        "    input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Initial convolution\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "    # Inception modules\n",
        "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
        "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=2)(x)\n",
        "\n",
        "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
        "\n",
        "    # Global average pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer, name=\"Inception\")\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nInception Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Key innovation: Parallel multi-scale convolutions!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "V8oTMCaWzkLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 7: ResNet (2015) - SKIP CONNECTIONS REVOLUTION"
      ],
      "metadata": {
        "id": "sDF1QI8I63o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 7: ResNet (2015) - SKIP CONNECTIONS REVOLUTION\n",
        "# ============================================================================\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    \"\"\"\n",
        "    Create a residual block.\n",
        "\n",
        "    Residual block concept:\n",
        "    - Add skip connection from input to output\n",
        "    - Allows training very deep networks (100+ layers)\n",
        "    - Solves vanishing gradient problem\n",
        "    - F(x) + x instead of just F(x)\n",
        "\n",
        "    This is the KEY innovation of ResNet!\n",
        "\n",
        "    Args:\n",
        "        x: Input tensor\n",
        "        filters: Number of filters\n",
        "        kernel_size: Size of conv kernel\n",
        "        stride: Stride for conv\n",
        "\n",
        "    Returns:\n",
        "        Output tensor with residual connection\n",
        "    \"\"\"\n",
        "    # Main path\n",
        "    shortcut = x\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # First conv layer: filters, kernel_size, padding='same', activation='relu'\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride,\n",
        "                     padding='________', activation='________')(x)\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Second conv layer: filters, kernel_size, padding='same', NO activation\n",
        "    x = layers.Conv2D(________, kernel_size, padding='________')(x)\n",
        "\n",
        "    # Adjust shortcut if dimensions changed\n",
        "    if stride != 1:\n",
        "        shortcut = layers.Conv2D(filters, (1, 1), strides=stride, padding='same')(shortcut)\n",
        "\n",
        "    # TODO: STUDENT FILL IN\n",
        "    # Add skip connection: x + shortcut\n",
        "    x = layers.add([________, ________])\n",
        "\n",
        "    # Activation after addition\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def create_resnet():\n",
        "    \"\"\"\n",
        "    Create ResNet architecture (simplified for CIFAR-10).\n",
        "\n",
        "    Original ResNet (2015) by He et al:\n",
        "    - Winner of ImageNet 2015\n",
        "    - Revolutionary skip connections\n",
        "    - Enabled training of very deep networks (152 layers!)\n",
        "    - Solved vanishing gradient problem\n",
        "\n",
        "    Key innovation:\n",
        "    - Residual/skip connections: x + F(x)\n",
        "    - Identity mapping\n",
        "    - Can train much deeper networks\n",
        "\n",
        "    Returns:\n",
        "        keras.Model: Compiled ResNet model\n",
        "    \"\"\"\n",
        "    print(\"\\nSTEP 7: BUILDING ResNet (2015)\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Innovation: Skip connections enable very deep networks!\")\n",
        "\n",
        "    input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Initial convolution\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = residual_block(x, 128, stride=2)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 256, stride=2)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    # Global average pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer, name=\"ResNet\")\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nResNet Architecture:\")\n",
        "    model.summary()\n",
        "    print(\"Key innovation: Skip connections (x + F(x))!\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tifSB1ppzmky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING AND EVALUATION FUNCTIONS"
      ],
      "metadata": {
        "id": "wrd0IMZb68eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# TRAINING AND EVALUATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=128):\n",
        "    \"\"\"Train a model and return history and training time.\"\"\"\n",
        "    print(f\"\\nTraining {model.name}...\")\n",
        "    print(f\"Epochs: {epochs}, Batch size: {batch_size}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    print(f\"{model.name} training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "    return history, training_time\n",
        "\n",
        "def evaluate_model(model, x_test, y_test, class_names):\n",
        "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
        "    print(f\"\\nEvaluating {model.name}...\")\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"{model.name} Results:\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "fe0W5AQpzp1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPARISON AND VISUALIZATION"
      ],
      "metadata": {
        "id": "V8x2SB9c7BKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# COMPARISON AND VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def compare_all_models(results):\n",
        "    \"\"\"\n",
        "    Compare all models with comprehensive analysis.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary with model results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 8: COMPREHENSIVE MODEL COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nðŸ“Š PERFORMANCE SUMMARY:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Model':<20} {'Accuracy':<12} {'Loss':<12} {'Time (s)':<12} {'Params':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for name, data in results.items():\n",
        "        print(f\"{name:<20} {data['accuracy']:<12.4f} {data['loss']:<12.4f} \"\n",
        "              f\"{data['time']:<12.2f} {data['params']:<12,}\")\n",
        "\n",
        "    print(\"\\nðŸ† RANKINGS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Sort by accuracy\n",
        "    sorted_by_acc = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
        "    print(\"\\nBy Accuracy:\")\n",
        "    for i, (name, data) in enumerate(sorted_by_acc, 1):\n",
        "        print(f\"  {i}. {name}: {data['accuracy']:.4f}\")\n",
        "\n",
        "    # Sort by parameters (efficiency)\n",
        "    sorted_by_params = sorted(results.items(), key=lambda x: x[1]['params'])\n",
        "    print(\"\\nBy Efficiency (fewer parameters):\")\n",
        "    for i, (name, data) in enumerate(sorted_by_params, 1):\n",
        "        print(f\"  {i}. {name}: {data['params']:,} params\")\n",
        "\n",
        "def plot_architecture_comparison(results):\n",
        "    \"\"\"Plot comparison of all architectures.\"\"\"\n",
        "    models = list(results.keys())\n",
        "    accuracies = [results[m]['accuracy'] for m in models]\n",
        "    params = [results[m]['params'] / 1e6 for m in models]  # in millions\n",
        "    times = [results[m]['time'] for m in models]\n",
        "\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Accuracy comparison\n",
        "    colors = ['red', 'orange', 'yellow', 'lightgreen', 'cyan', 'blue']\n",
        "    ax1.bar(models, accuracies, color=colors)\n",
        "    ax1.set_title('Test Accuracy Comparison')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_ylim([0, 1])\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    for i, v in enumerate(accuracies):\n",
        "        ax1.text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
        "\n",
        "    # Parameters comparison\n",
        "    ax2.bar(models, params, color=colors)\n",
        "    ax2.set_title('Model Complexity (Parameters)')\n",
        "    ax2.set_ylabel('Parameters (Millions)')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    for i, v in enumerate(params):\n",
        "        ax2.text(i, v + 0.1, f'{v:.2f}M', ha='center')\n",
        "\n",
        "    # Training time comparison\n",
        "    ax3.bar(models, times, color=colors)\n",
        "    ax3.set_title('Training Time (10 epochs)')\n",
        "    ax3.set_ylabel('Time (seconds)')\n",
        "    ax3.tick_params(axis='x', rotation=45)\n",
        "    for i, v in enumerate(times):\n",
        "        ax3.text(i, v + 5, f'{v:.1f}s', ha='center')\n",
        "\n",
        "    # Accuracy vs Parameters scatter\n",
        "    ax4.scatter(params, accuracies, c=range(len(models)), cmap='viridis', s=200)\n",
        "    for i, model in enumerate(models):\n",
        "        ax4.annotate(model, (params[i], accuracies[i]),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "    ax4.set_xlabel('Parameters (Millions)')\n",
        "    ax4.set_ylabel('Accuracy')\n",
        "    ax4.set_title('Accuracy vs Model Complexity')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cnn_architecture_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nðŸ“ˆ Comparison plot saved as 'cnn_architecture_comparison.png'\")\n",
        "\n",
        "def analyze_evolution():\n",
        "    \"\"\"Analyze the evolution of CNN architectures.\"\"\"\n",
        "    print(\"\\nðŸ”¬ ARCHITECTURAL EVOLUTION ANALYSIS:\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\n1998 - LeNet-5:\")\n",
        "    print(\"  â€¢ Pioneer of CNNs\")\n",
        "    print(\"  â€¢ Small network, tanh activation\")\n",
        "    print(\"  â€¢ Designed for simple tasks (MNIST)\")\n",
        "\n",
        "    print(\"\\n2012 - AlexNet:\")\n",
        "    print(\"  â€¢ Deep learning revolution\")\n",
        "    print(\"  â€¢ ReLU activation (faster training)\")\n",
        "    print(\"  â€¢ Dropout regularization\")\n",
        "    print(\"  â€¢ Won ImageNet competition\")\n",
        "\n",
        "    print(\"\\n2014 - VGG-16:\")\n",
        "    print(\"  â€¢ Very deep (16 layers)\")\n",
        "    print(\"  â€¢ Uniform 3x3 convolutions\")\n",
        "    print(\"  â€¢ Simple but effective architecture\")\n",
        "\n",
        "    print(\"\\n2014 - Inception:\")\n",
        "    print(\"  â€¢ Multi-scale feature extraction\")\n",
        "    print(\"  â€¢ Parallel convolutions (1x1, 3x3, 5x5)\")\n",
        "    print(\"  â€¢ More efficient than VGG\")\n",
        "\n",
        "    print(\"\\n2015 - ResNet:\")\n",
        "    print(\"  â€¢ Skip connections revolution\")\n",
        "    print(\"  â€¢ Enables very deep networks (100+ layers)\")\n",
        "    print(\"  â€¢ Solved vanishing gradient problem\")\n",
        "    print(\"  â€¢ State-of-the-art performance\")\n",
        "\n",
        "    print(\"\\nðŸŽ¯ KEY LESSONS:\")\n",
        "    print(\"  1. Depth matters (but needs skip connections)\")\n",
        "    print(\"  2. ReLU > tanh/sigmoid\")\n",
        "    print(\"  3. Regularization prevents overfitting\")\n",
        "    print(\"  4. Multi-scale features improve performance\")\n",
        "    print(\"  5. Skip connections enable deeper networks\")"
      ],
      "metadata": {
        "id": "gUVrZUXnzt6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN EXECUTION - SEQUENTIAL TRAINING"
      ],
      "metadata": {
        "id": "oSLlfU4c7EWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NIf8Frsy2RS"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION - SEQUENTIAL TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"CNN ARCHITECTURE EVOLUTION: LeNet to ResNet\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Train each architecture sequentially\n",
        "architectures = [\n",
        "    (\"Traditional CNN\", create_traditional_cnn),\n",
        "    (\"LeNet-5\", create_lenet5),\n",
        "    (\"AlexNet\", create_alexnet),\n",
        "    (\"VGG-16\", create_vgg16),\n",
        "    (\"Inception\", create_inception),\n",
        "    (\"ResNet\", create_resnet)\n",
        "]\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "for name, create_func in architectures:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TRAINING: {name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create model\n",
        "    model = create_func()\n",
        "\n",
        "    # Train model\n",
        "    history, training_time = train_model(model, x_train, y_train, x_test, y_test,\n",
        "                                        epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Evaluate model\n",
        "    test_loss, test_accuracy = evaluate_model(model, x_test, y_test, class_names)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'accuracy': test_accuracy,\n",
        "        'loss': test_loss,\n",
        "        'time': training_time,\n",
        "        'params': model.count_params(),\n",
        "        'history': history\n",
        "    }\n",
        "\n",
        "    print(f\"\\nâœ… {name} completed!\")\n",
        "\n",
        "# Compare all models\n",
        "compare_all_models(results)\n",
        "plot_architecture_comparison(results)\n",
        "analyze_evolution()\n",
        "\n",
        "print(\"\\nðŸŽ‰ EXERCISE COMPLETED!\")\n",
        "print(\"You've explored the evolution of CNN architectures from 1998 to 2015!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸŽ“ DISCUSSION QUESTIONS:\n",
        "\n",
        "1. Why did AlexNet outperform LeNet-5?\n",
        "   Hint: Think about activation functions and depth\n",
        "\n",
        "2. Why does VGG-16 have so many parameters?\n",
        "   Hint: Look at the fully connected layers\n",
        "\n",
        "3. How does Inception achieve efficiency?\n",
        "   Hint: Compare parameters with VGG-16\n",
        "\n",
        "4. Why can ResNet train much deeper networks?\n",
        "   Hint: Think about gradient flow\n",
        "\n",
        "5. Trade-offs: Accuracy vs Parameters vs Speed?\n",
        "   Which architecture would you choose for:\n",
        "   - Mobile device (limited resources)\n",
        "   - Cloud server (unlimited resources)\n",
        "   - Real-time application (speed critical)\n",
        "\n",
        "ðŸ”¬ EXPERIMENTS TO TRY:\n",
        "\n",
        "1. Train for more epochs - which improves most?\n",
        "2. Add data augmentation - impact on each architecture?\n",
        "3. Reduce/increase model depth - what happens?\n",
        "4. Try different optimizers (SGD vs Adam)\n",
        "5. Implement batch normalization in older architectures\n",
        "\n",
        "ðŸ“š FURTHER LEARNING:\n",
        "\n",
        "- EfficientNet (2019): Compound scaling\n",
        "- Vision Transformer (2020): Attention mechanisms\n",
        "- ConvNeXt (2022): Modern CNN design\n"
      ],
      "metadata": {
        "id": "86YpsAg-zxx4"
      }
    }
  ]
}